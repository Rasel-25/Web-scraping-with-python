{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='quotes.toscrape.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001ED1A927D30>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=172'>173</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=173'>174</a>\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39mcreate_connection(\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=174'>175</a>\u001b[0m         (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dns_host, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=175'>176</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=177'>178</a>\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/urllib3/util/connection.py?line=67'>68</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m six\u001b[39m.\u001b[39mraise_from(\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/urllib3/util/connection.py?line=68'>69</a>\u001b[0m         LocationParseError(\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m host), \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/urllib3/util/connection.py?line=69'>70</a>\u001b[0m     )\n\u001b[1;32m---> <a href='file:///c%3A/Python310/lib/site-packages/urllib3/util/connection.py?line=71'>72</a>\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/urllib3/util/connection.py?line=72'>73</a>\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Python310\\lib\\socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/socket.py?line=953'>954</a>\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/socket.py?line=954'>955</a>\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/socket.py?line=955'>956</a>\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=701'>702</a>\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=702'>703</a>\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=703'>704</a>\u001b[0m     conn,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=704'>705</a>\u001b[0m     method,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=705'>706</a>\u001b[0m     url,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=706'>707</a>\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=707'>708</a>\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=708'>709</a>\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=709'>710</a>\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=710'>711</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=712'>713</a>\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=713'>714</a>\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=714'>715</a>\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=715'>716</a>\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=384'>385</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=385'>386</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=386'>387</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=387'>388</a>\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:1040\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=1038'>1039</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=1039'>1040</a>\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=1041'>1042</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=355'>356</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=356'>357</a>\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=357'>358</a>\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=358'>359</a>\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=184'>185</a>\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=185'>186</a>\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=186'>187</a>\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=187'>188</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connection.py?line=189'>190</a>\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000001ED1A927D30>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\requests\\adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=439'>440</a>\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=440'>441</a>\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=441'>442</a>\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=442'>443</a>\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=443'>444</a>\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=444'>445</a>\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=445'>446</a>\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=446'>447</a>\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=447'>448</a>\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=448'>449</a>\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=449'>450</a>\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=450'>451</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=452'>453</a>\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=453'>454</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:785\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=782'>783</a>\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=784'>785</a>\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=785'>786</a>\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=786'>787</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/connectionpool.py?line=787'>788</a>\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/util/retry.py?line=590'>591</a>\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/urllib3/util/retry.py?line=591'>592</a>\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/urllib3/util/retry.py?line=593'>594</a>\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='quotes.toscrape.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001ED1A927D30>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32me:\\DATA SCIENCE\\PYTHON\\Web-scraping-with-python\\Web Scrap basic\\toscrape.ipynb Cell 2'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/DATA%20SCIENCE/PYTHON/Web-scraping-with-python/Web%20Scrap%20basic/toscrape.ipynb#ch0000001?line=0'>1</a>\u001b[0m res\u001b[39m=\u001b[39mrequests\u001b[39m.\u001b[39;49mget(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhttps://quotes.toscrape.com\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/DATA%20SCIENCE/PYTHON/Web-scraping-with-python/Web%20Scrap%20basic/toscrape.ipynb#ch0000001?line=1'>2</a>\u001b[0m res\u001b[39m.\u001b[39mok\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\requests\\api.py:75\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/requests/api.py?line=63'>64</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/requests/api.py?line=64'>65</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/requests/api.py?line=65'>66</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/requests/api.py?line=66'>67</a>\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/requests/api.py?line=71'>72</a>\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/requests/api.py?line=72'>73</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Python310/lib/site-packages/requests/api.py?line=74'>75</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39m\u001b[39mget\u001b[39m\u001b[39m'\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\requests\\api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/requests/api.py?line=56'>57</a>\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/requests/api.py?line=57'>58</a>\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/requests/api.py?line=58'>59</a>\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python310/lib/site-packages/requests/api.py?line=59'>60</a>\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> <a href='file:///c%3A/Python310/lib/site-packages/requests/api.py?line=60'>61</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\requests\\sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/sessions.py?line=523'>524</a>\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/sessions.py?line=524'>525</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/sessions.py?line=525'>526</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/sessions.py?line=526'>527</a>\u001b[0m }\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/sessions.py?line=527'>528</a>\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/requests/sessions.py?line=528'>529</a>\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/sessions.py?line=530'>531</a>\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\requests\\sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/sessions.py?line=641'>642</a>\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/sessions.py?line=643'>644</a>\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/requests/sessions.py?line=644'>645</a>\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/sessions.py?line=646'>647</a>\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/sessions.py?line=647'>648</a>\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\requests\\adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=514'>515</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=515'>516</a>\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=516'>517</a>\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m--> <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=518'>519</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=520'>521</a>\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Python310/lib/site-packages/requests/adapters.py?line=521'>522</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='quotes.toscrape.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001ED1A927D30>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "res=requests.get(r'https://quotes.toscrape.com')\n",
    "res.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bs4 — BeautifulSoup 4\n",
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files\n",
    "Beautiful Soup is a library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser, providing Pythonic idioms for iterating, searching, and modifying the parse tree.\n",
    "It commonly saves programmers hours or days of work.\n",
    "\n",
    "Beautiful Soup is a library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser, providing Pythonic idioms for iterating, searching, and modifying the parse tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lxml\n",
    "lxml is a Python library which allows for easy handling of XML and HTML files, and can also be used for web scraping. There are a lot of off-the-shelf XML parsers out there, but for better results, developers sometimes prefer to write their own XML and HTML parsers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may be the name of a specific parser (\"lxml\", \"lxml-xml\", \"html.parser\", or \"html5lib\") or it may be the type of markup to be used (\"html\", \"html5\", \"xml\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(res.content,'lxml') # \n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title # getting title with tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head  # getting head of the HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body   # getting body of the HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.text # getting only title text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('title') # return single tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('title').string # text / string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('head') # return multiple tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.link # return single link "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('link') # return multiple link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.link.attrs # return link as list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.find_all('a'): # extract all the URLs within a webpage\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.link.attrs['href'] # return only link text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('div', attrs={'class':'quote'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch the quote\n",
    "soup.find('div',attrs={'class':'quote'}).span.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch the author\n",
    "soup.find('div',attrs={'class':'quote'}).find('small',attrs={'class':'author'}).string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the tags\n",
    "tags=soup.find('div',attrs={'class':'quote'}).find('div',attrs={'class':'tags'}).find_all('a')\n",
    "tags\n",
    "for tag in tags:\n",
    "    print(tag.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Python for loop one line with list comprehension\n",
    "   \n",
    "   Syntax \n",
    "   new_list = [expression for member in iterable]\n",
    " \n",
    "    my_list = [n*n for n in range(1, 10)]\n",
    "    print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return all iterable string \n",
    "database=[]\n",
    "for quote in soup.find_all('div',attrs={'class': 'quote'}):\n",
    "    q=quote.span.string\n",
    "    \n",
    "    database.append(q)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return all iterable author \n",
    "database=[]\n",
    "for quote in soup.find_all('div',attrs={'class': 'quote'}):\n",
    "    q=quote.span.string\n",
    "    author=quote.find('small',attrs={'class':'author'}).string\n",
    "    database.append(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return all iterable tags\n",
    "#  \n",
    "database=[]\n",
    "for quote in soup.find_all('div',attrs={'class': 'quote'}):\n",
    "    q=quote.span.string\n",
    "    #author=quote.find('small',attrs={'class':'author'}).string\n",
    "    tags=[tag.string for tag in quote.find('div',attrs={'class':'tags'}).find_all('a') ]\n",
    "    database.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return all iterable  \n",
    "database=[]\n",
    "for quote in soup.find_all('div',attrs={'class': 'quote'}):\n",
    "    q=quote.span.string\n",
    "    author=quote.find('small',attrs={'class':'author'}).string\n",
    "    tags=[tag.string for tag in quote.find('div',attrs={'class':'tags'}).find_all('a') ]\n",
    "    database.append([q,author,tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('li',attrs={'class':'next'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup.find('li',class_='next').a.attrs['href'] # class_='next' smilat to attrs={'class':'next'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPage(soup:BeautifulSoup):\n",
    "    tempData=[]\n",
    "    for quote in soup.find_all('div',attrs={'class': 'quote'}):\n",
    "        q=quote.span.string\n",
    "        author=quote.find('small',attrs={'class':'author'}).string\n",
    "        tags='#'.join([tag.string for tag in quote.find('div',attrs={'class':'tags'}).find_all('a')])\n",
    "        tempData.append([q,author,tags])\n",
    "    return tempData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url=r'https://quotes.toscrape.com'\n",
    "resp=requests.get(start_url)\n",
    "#resp.content\n",
    "Database = []\n",
    "while True:\n",
    "    try:\n",
    "        soup=BeautifulSoup(resp.content)\n",
    "        extractedQuote=extractPage(soup)\n",
    "        Database = Database + extractedQuote # store all data into database\n",
    "        neext=soup.find('li',attrs={'class':'next'}).a.attrs['href'] # return '/page/10/'\n",
    "        url=start_url+neext # return all url\n",
    "        print(url)\n",
    "        resp = requests.get(url)\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print('Successfully all pages Extracted!')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Database[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Database[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv.writer\n",
    "There are various classes provided by this module for writing to CSV:\n",
    "\n",
    "1) Using csv.writer class\n",
    "2) Using csv.DictWriter class\n",
    "\n",
    "Using csv.writer class\n",
    "csv.writer class is used to insert data to the CSV file. This class returns a writer object which is responsible for converting the user’s data into a delimited string. A csvfile object should be opened with newline='' otherwise newline characters inside the quoted fields will not be interpreted correctly.\n",
    "\n",
    "Syntax: csv.writer(csvfile, dialect=’excel’, **fmtparams)\n",
    "\n",
    "Parameters:\n",
    "csvfile: A file object with write() method.\n",
    "dialect (optional): Name of the dialect to be used.\n",
    "fmtparams (optional): Formatting parameters that will overwrite those specified in the dialect.\n",
    "\n",
    "csv.writer class provides two methods for writing to CSV. They are writerow() and writerows().\n",
    "\n",
    "writerow(): This method writes a single row at a time. Field row can be written using this method.\n",
    "Syntax:\n",
    "writerow(fields)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encode()\n",
    "The encode() method encodes the string, using the specified encoding. If no encoding is specified, UTF-8 will be used.\n",
    "\n",
    "A String specifying the encoding to use. Default is UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# writing to csv file \n",
    "with open('Quotes.csv', mode='w', newline='', encoding='utf-8') as f: # newline='' add new line\n",
    "    \n",
    "    writer = csv.writer(f, delimiter='|')  # creating a csv writer object \n",
    "    writer.writerow(['Quote', 'Author', 'Tags'])   # writing the fields/heading name. \n",
    "    writer.writerows(Database)    # writing the data rows "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
